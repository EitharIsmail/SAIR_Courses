{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö PyTorch Practice Notebook - Lecture 3: Convolutional Neural Networks\n",
    "\n",
    "**Based on:** SAIR PyTorch Mastery - Lecture 3: Convolutional Neural Networks - Vision & Beyond\n",
    "\n",
    "**Instructions:** Complete the exercises below to test your understanding of CNNs and computer vision with PyTorch. Try to solve them without looking at the original notebook first!\n",
    "\n",
    "**Time Estimate:** 3-4 hours\n",
    "\n",
    "## üÜï Enhanced Features:\n",
    "- Mathematical foundation exercises\n",
    "- Visualization and interpretation tasks\n",
    "- Debugging CNN architectures\n",
    "- Performance analysis\n",
    "- Sudanese context applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup & Imports\n",
    "\n",
    "Run this cell first to set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜï NEW: Debugging Exercise 0 - Find the CNN Bugs!\n",
    "\n",
    "**Task:** This CNN class has multiple bugs. Identify and fix them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== BUGGY CNN - FIND AND FIX ALL BUGS! ===========\n",
    "class BuggyCNN(nn.Module):\n",
    "    \"\"\"CNN with multiple bugs - fix them all!\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        # BUG 1: Missing super().__init__()\n",
    "        \n",
    "        # BUG 2: Inconsistent channel sizes\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=0)  # Will reduce size too much\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=0)  # Inconsistent padding\n",
    "        \n",
    "        # BUG 3: Wrong calculation of flattened size\n",
    "        # For 32x32 input with kernel=5, stride=1, padding=0:\n",
    "        # conv1: 32 -> 28, conv2: 28 -> 24\n",
    "        # After maxpool (2x): 24 -> 12\n",
    "        # So flattened size should be 64 * 12 * 12 = 9216\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 256)  # Wrong!\n",
    "        \n",
    "        # BUG 4: Wrong number of classes parameter\n",
    "        self.fc2 = nn.Linear(256, 100)  # Should be num_classes\n",
    "        \n",
    "        # BUG 5: Missing activation functions\n",
    "        # Should add ReLU\n",
    "        \n",
    "        # BUG 6: Missing pooling layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # BUG 7: Wrong order of operations\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)  # Should pool between convs\n",
    "        \n",
    "        # BUG 8: Wrong reshape dimensions\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)  # This is correct but after wrong flattening calc\n",
    "        \n",
    "        # BUG 9: Missing activation functions\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # BUG 10: No output activation for classification\n",
    "        return x\n",
    "\n",
    "# =========== YOUR FIXED VERSION ===========\n",
    "class FixedCNN(nn.Module):\n",
    "    \"\"\"Your fixed version of the buggy CNN\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # TODO: Fix all bugs\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Fix forward pass\n",
    "        pass\n",
    "\n",
    "# Test with a sample input\n",
    "print(\"Testing Buggy CNN:\")\n",
    "test_input = torch.randn(4, 3, 32, 32)  # batch_size=4, RGB, 32x32\n",
    "buggy_model = BuggyCNN()\n",
    "try:\n",
    "    output = buggy_model(test_input)\n",
    "    print(f\"Buggy output shape: {output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Buggy model error: {e}\")\n",
    "\n",
    "print(\"\\nTesting Fixed CNN:\")\n",
    "fixed_model = FixedCNN()\n",
    "# TODO: Test your fixed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Exercise 1: Mathematical Foundations & Manual Implementation\n",
    "\n",
    "### Part A: Manual 2D Convolution\n",
    "\n",
    "**Task:** Implement 2D convolution from scratch without using PyTorch's `nn.Conv2d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== YOUR CODE HERE ===========\n",
    "def manual_conv2d(image, kernel, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Perform 2D convolution manually.\n",
    "    \n",
    "    Args:\n",
    "        image: 2D numpy array (H, W)\n",
    "        kernel: 2D numpy array (kH, kW)\n",
    "        stride: Stride value\n",
    "        padding: Padding value\n",
    "    \n",
    "    Returns:\n",
    "        output: 2D numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Add padding if specified\n",
    "    \n",
    "    # TODO: Get dimensions\n",
    "    \n",
    "    # TODO: Calculate output dimensions\n",
    "    \n",
    "    # TODO: Create output array\n",
    "    \n",
    "    # TODO: Perform convolution (sliding window)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Test your implementation\n",
    "print(\"Testing Manual Convolution:\")\n",
    "\n",
    "# Create test image\n",
    "test_image = np.array([\n",
    "    [1, 2, 3, 0, 1],\n",
    "    [4, 5, 6, 1, 2],\n",
    "    [7, 8, 9, 2, 3],\n",
    "    [0, 1, 2, 3, 4],\n",
    "    [1, 2, 3, 4, 5]\n",
    "])\n",
    "\n",
    "# Test with different kernels\n",
    "identity_kernel = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 0]\n",
    "])\n",
    "\n",
    "edge_kernel = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1]\n",
    "])\n",
    "\n",
    "blur_kernel = np.ones((3, 3)) / 9\n",
    "\n",
    "# TODO: Test your function with different kernels\n",
    "# Compare with PyTorch's implementation for verification\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Convolution Mathematics - Shape Calculations\n",
    "\n",
    "**Task:** Create a function that calculates output dimensions for convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== YOUR CODE HERE ===========\n",
    "def calculate_output_size(input_size, kernel_size, stride=1, padding=0, dilation=1):\n",
    "    \"\"\"\n",
    "    Calculate output size for convolution.\n",
    "    \n",
    "    Formula: output = floor((input + 2*padding - dilation*(kernel-1) - 1) / stride) + 1\n",
    "    \n",
    "    Args:\n",
    "        input_size: Input dimension (H or W)\n",
    "        kernel_size: Kernel dimension\n",
    "        stride: Stride value\n",
    "        padding: Padding value\n",
    "        dilation: Dilation value\n",
    "    \n",
    "    Returns:\n",
    "        output_size: Calculated output dimension\n",
    "    \"\"\"\n",
    "    # TODO: Implement the formula\n",
    "    pass\n",
    "\n",
    "def calculate_cnn_output_shape(input_shape, conv_layers):\n",
    "    \"\"\"\n",
    "    Calculate final output shape after multiple convolutional layers.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Tuple (C, H, W)\n",
    "        conv_layers: List of dicts with layer parameters\n",
    "            Example: [{'type': 'conv', 'out_channels': 32, 'kernel': 3, 'stride': 1, 'padding': 1},\n",
    "                      {'type': 'pool', 'kernel': 2, 'stride': 2}]\n",
    "    \n",
    "    Returns:\n",
    "        output_shape: Tuple (C, H, W)\n",
    "    \"\"\"\n",
    "    # TODO: Track shape through layers\n",
    "    pass\n",
    "\n",
    "# Test cases\n",
    "print(\"Test Cases for Shape Calculations:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test 1: Simple convolution\n",
    "test1 = calculate_output_size(32, 3, stride=1, padding=1)\n",
    "print(f\"Test 1 - Input 32, kernel 3, stride 1, padding 1: {test1} (expected: 32)\")\n",
    "\n",
    "# Test 2: With pooling\n",
    "test2 = calculate_output_size(32, 2, stride=2)  # MaxPool2d(2)\n",
    "print(f\"Test 2 - Input 32, kernel 2, stride 2 (pooling): {test2} (expected: 16)\")\n",
    "\n",
    "# Test 3: Complex CNN\n",
    "layers = [\n",
    "    {'type': 'conv', 'out_channels': 32, 'kernel': 3, 'stride': 1, 'padding': 1},\n",
    "    {'type': 'pool', 'kernel': 2, 'stride': 2},\n",
    "    {'type': 'conv', 'out_channels': 64, 'kernel': 3, 'stride': 1, 'padding': 1},\n",
    "    {'type': 'pool', 'kernel': 2, 'stride': 2},\n",
    "]\n",
    "\n",
    "input_shape = (3, 32, 32)  # CIFAR-10\n",
    "output_shape = calculate_cnn_output_shape(input_shape, layers)\n",
    "print(f\"\\nComplex CNN shape calculation:\")\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Output shape: {output_shape}\")\n",
    "print(f\"Flattened size: {output_shape[0] * output_shape[1] * output_shape[2]}\")\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üÜï NEW: Part C: Kernel Visualization Challenge\n",
    "\n",
    "**Task:** Create a visualization tool that shows what different kernels do to images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelVisualizer:\n",
    "    \"\"\"Visualize different convolution kernels\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.kernels = {\n",
    "            'identity': np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]]),\n",
    "            'edge_detection': np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]),\n",
    "            'sobel_x': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n",
    "            'sobel_y': np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),\n",
    "            'sharpen': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n",
    "            'box_blur': np.ones((3, 3)) / 9,\n",
    "            'gaussian_blur': np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16,\n",
    "        }\n",
    "    \n",
    "    def visualize_kernels(self):\n",
    "        \"\"\"Visualize all kernels\"\"\"\n",
    "        # TODO: Create a grid plot of all kernels\n",
    "        pass\n",
    "    \n",
    "    def apply_to_image(self, image, kernel_name):\n",
    "        \"\"\"Apply kernel to image and show result\"\"\"\n",
    "        # TODO: Apply convolution and show before/after\n",
    "        pass\n",
    "    \n",
    "    def create_custom_kernel(self, weights):\n",
    "        \"\"\"Create and test a custom kernel\"\"\"\n",
    "        # TODO: Allow user to create custom kernels\n",
    "        pass\n",
    "\n",
    "# Test the visualizer\n",
    "print(\"Testing Kernel Visualizer:\")\n",
    "visualizer = KernelVisualizer()\n",
    "visualizer.visualize_kernels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Exercise 2: Building CNN Architectures\n",
    "\n",
    "### Part A: Build SimpleCNN from Specifications\n",
    "\n",
    "**Task:** Build a CNN based on these specifications:\n",
    "\n",
    "**Requirements:**\n",
    "1. Input: 32x32 RGB images (CIFAR-10)\n",
    "2. Architecture:\n",
    "   - Conv1: 32 filters, 3x3, padding=1 ‚Üí ReLU ‚Üí BatchNorm ‚Üí MaxPool(2)\n",
    "   - Conv2: 64 filters, 3x3, padding=1 ‚Üí ReLU ‚Üí BatchNorm ‚Üí MaxPool(2)\n",
    "   - Conv3: 128 filters, 3x3, padding=1 ‚Üí ReLU ‚Üí BatchNorm ‚Üí MaxPool(2)\n",
    "   - Flatten\n",
    "   - FC1: 256 units ‚Üí ReLU ‚Üí Dropout(0.3)\n",
    "   - FC2: 128 units ‚Üí ReLU ‚Üí Dropout(0.3)\n",
    "   - Output: 10 units (softmax in loss)\n",
    "\n",
    "3. Total parameters should be less than 500,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== YOUR CODE HERE ===========\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"Your implementation of SimpleCNN\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # TODO: Implement the architecture\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Count total and trainable parameters\"\"\"\n",
    "        total = sum(p.numel() for p in self.parameters())\n",
    "        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        return total, trainable\n",
    "\n",
    "# Test your model\n",
    "print(\"Testing SimpleCNN:\")\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(4, 3, 32, 32)  # batch_size=4\n",
    "output = model(test_input)\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params, trainable_params = model.count_parameters()\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Under 500,000? {total_params < 500000}\")\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "# ==========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Build LeNet (Adapted for CIFAR-10)\n",
    "\n",
    "**Task:** Implement AlexLeNetNet architecture adapted for 32x32 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, num_classes=10):\n",
    "    super().__init__()\n",
    "    \n",
    "    # TODO: Implement LeNet-5 architecture for CIFAR-10\n",
    "    # Original LeNet-5 (for 32x32 images):\n",
    "    # 1. Conv2d: 1 input channel ‚Üí 6 output channels, kernel=5x5\n",
    "    # 2. Tanh activation\n",
    "    # 3. AvgPool2d: kernel=2x2, stride=2\n",
    "    # 4. Conv2d: 6 input channels ‚Üí 16 output channels, kernel=5x5\n",
    "    # 5. Tanh activation\n",
    "    # 6. AvgPool2d: kernel=2x2, stride=2\n",
    "    # 7. Flatten\n",
    "    # 8. Linear: ? features ‚Üí 120 units\n",
    "    # 9. Tanh activation\n",
    "    # 10. Linear: 120 ‚Üí 84 units\n",
    "    # 11. Tanh activation\n",
    "    # 12. Linear: 84 ‚Üí num_classes\n",
    "    \n",
    "    # Hints for CIFAR-10 adaptation:\n",
    "    # - CIFAR-10 has 3 input channels (RGB) not 1 (grayscale)\n",
    "    # - Input size is 32x32 (same as original LeNet paper)\n",
    "    # - Need to calculate the flattened size after conv/pool layers\n",
    "    \n",
    "    # TODO: Define the convolutional layers (features extractor)\n",
    "    self.features = nn.Sequential(\n",
    "        # Layer 1\n",
    "        # TODO: First convolutional layer\n",
    "        \n",
    "        # TODO: Activation function (Tanh)\n",
    "        \n",
    "        # TODO: Pooling layer\n",
    "    )\n",
    "    \n",
    "    # TODO: Calculate the flattened size\n",
    "    # After first conv (32x32 ‚Üí ?x?): \n",
    "    # output_size = (input_size + 2*padding - kernel_size) / stride + 1\n",
    "    # After first pool: ?x? ‚Üí ?x?\n",
    "    # After second conv: ?x? ‚Üí ?x?\n",
    "    # After second pool: ?x? ‚Üí ?x?\n",
    "    # flattened_size = channels * height * width\n",
    "    \n",
    "    # TODO: Define the fully connected layers (classifier)\n",
    "    self.classifier = nn.Sequential(\n",
    "        # TODO: Flatten layer\n",
    "        \n",
    "        # TODO: First fully connected layer\n",
    "        \n",
    "        # TODO: Activation function\n",
    "        \n",
    "        # TODO: Second fully connected layer\n",
    "        \n",
    "        # TODO: Activation function\n",
    "        \n",
    "        # TODO: Output layer\n",
    "    )\n",
    "\n",
    "def forward(self, x):\n",
    "    # TODO: Implement the forward pass\n",
    "    # Hint: Pass through features, then classifier\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Exercise 3: Complete Training & Evaluation\n",
    "\n",
    "\n",
    "**Task:** Write a complete training loop for cats vs dogs with proper validation and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cats vs dogs dataset\n",
    "# pre[are the dataset and dataloader \n",
    "# defined the model \n",
    "# train and evaluate the model \n",
    "# plot the results \n",
    "# and save the model \n",
    "# [BONUS] test the model on new images + visualize feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Challenge Problems\n",
    "\n",
    "### Challenge 1: Optimize CNN for Mobile Deployment\n",
    "\n",
    "**Task:** Create a lightweight CNN for mobile deployment in Sudanese farms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileSudaneseCNN(nn.Module):\n",
    "    \"\"\"Lightweight CNN for mobile deployment\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO: Design a CNN with:\n",
    "        # 1. Less than 100,000 parameters\n",
    "        # 2. Fast inference on mobile CPU\n",
    "        # 3. Good accuracy for crop classification\n",
    "        \n",
    "        # Techniques to consider:\n",
    "        # - Depthwise separable convolutions\n",
    "        # - Bottleneck layers\n",
    "        # - Reduced channel counts\n",
    "        # - Efficient activation functions\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    def benchmark(self, input_size=(1, 3, 224, 224)):\n",
    "        \"\"\"Benchmark model performance\"\"\"\n",
    "        # TODO: Measure parameters, FLOPs, inference time\n",
    "        pass\n",
    "\n",
    "print(\"Testing Mobile CNN:\")\n",
    "mobile_cnn = MobileSudaneseCNN()\n",
    "mobile_cnn.benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Multi-Task CNN\n",
    "\n",
    "**Task:** Create a CNN that performs multiple tasks for Sudanese agriculture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskAgricultureCNN(nn.Module):\n",
    "    \"\"\"CNN for multiple agricultural tasks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Shared backbone\n",
    "        self.backbone = nn.Sequential(\n",
    "            # TODO: Shared convolutional layers\n",
    "        )\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.crop_classifier = nn.Sequential(\n",
    "            # TODO: Classify crop type (5 classes)\n",
    "        )\n",
    "        \n",
    "        self.health_classifier = nn.Sequential(\n",
    "            # TODO: Classify health status (3 classes)\n",
    "        )\n",
    "        \n",
    "        self.yield_regressor = nn.Sequential(\n",
    "            # TODO: Predict yield (continuous value)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        crop_pred = self.crop_classifier(features)\n",
    "        health_pred = self.health_classifier(features)\n",
    "        yield_pred = self.yield_regressor(features)\n",
    "        \n",
    "        return {\n",
    "            'crop_type': crop_pred,\n",
    "            'health_status': health_pred,\n",
    "            'yield': yield_pred\n",
    "        }\n",
    "    \n",
    "    def multi_task_loss(self, predictions, targets):\n",
    "        \"\"\"Compute combined loss for all tasks\"\"\"\n",
    "        # TODO: Weighted combination of:\n",
    "        # 1. Cross-entropy for crop classification\n",
    "        # 2. Cross-entropy for health classification\n",
    "        # 3. MSE for yield regression\n",
    "        pass\n",
    "\n",
    "print(\"Testing Multi-Task CNN:\")\n",
    "# TODO: Implement and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Assessment Questions\n",
    "\n",
    "Answer these questions in markdown cells:\n",
    "\n",
    "### Q1: What's the key difference between a dense layer and a convolutional layer? When would you use each?\n",
    "\n",
    "### Q2: How does padding affect convolution output size and feature learning?\n",
    "\n",
    "### Q3: Why do CNNs use small kernel sizes (3x3) instead of large ones?\n",
    "\n",
    "### Q4: What's the purpose of pooling layers in CNNs? What are the trade-offs between max pooling and average pooling?\n",
    "\n",
    "### Q5: How does BatchNorm help with CNN training? Why does it behave differently during training vs inference?\n",
    "\n",
    "### Q6: Explain the concept of \"receptive field\" in CNNs. How does it change through the network?\n",
    "\n",
    "### Q7: What's the difference between Conv1D, Conv2D, and Conv3D? Give real-world examples for each.\n",
    "\n",
    "### üÜï Q8: Design a CNN architecture for classifying Sudanese traditional clothing. What considerations would you make?\n",
    "\n",
    "### üÜï Q9: How would you optimize a CNN for deployment on mobile phones in rural Sudan?\n",
    "\n",
    "### üÜï Q10: Create a debugging checklist for when your CNN isn't learning (low accuracy).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You're ready for Lecture 4: Transfer Learning & Advanced Architectures!** üéâ\n",
    "\n",
    "## üí° Tips for Success\n",
    "\n",
    "1. **Start Simple**: Begin with manual convolution, then use PyTorch layers\n",
    "2. **Visualize Everything**: Use the visualization tools to understand what's happening\n",
    "3. **Test Shapes**: Always print tensor shapes between layers\n",
    "4. **Consider Sudanese Context**: Think about real applications in Sudan\n",
    "5. **Benchmark**: Compare different architectures and techniques\n",
    "6. **üÜï Debug Systematically**: When something doesn't work, check shapes, devices, gradients\n",
    "7. **üÜï Think About Deployment**: Consider computational constraints\n",
    "\n",
    "## ü§ù Need Help?\n",
    "\n",
    "- Review Lecture 3 notebook for concepts\n",
    "- Use PyTorch documentation for specific APIs\n",
    "- Test with small examples first\n",
    "- Visualize intermediate results\n",
    "- üÜï Create minimal reproducible examples when debugging\n",
    "- üÜï Benchmark different approaches to find optimal solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Important Note:\n",
    "# Go to Chapter 11 of Hands On Machine Learning with sklearn and PyTorch by Aur√©lien G√©ron.and solve the exercises at the end of the chapter.and add it in this notebook as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
